---
title: "Holsenbeck_S_5"
author: "Stephen Synchronicity"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
always_allow_html: yes
output: 
  html_document: 
    css: C:\Users\Stephen\Documents\R\win-library\3.4\rmarkdown\rmarkdown\templates\neu_hwk\resources\styles.css
    highlight: zenburn
    keep_md: yes
    theme: readable
    toc_float: true
    toc: yes
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE,warning=F,cache=TRUE, fig.align='center', fig.height=3.5, fig.width=5, tidy=TRUE, tidy.opts=list(width.cutoff=80))
rmarkdown::html_dependency_jquery()
rmarkdown::html_dependency_bootstrap("readable")
rmarkdown::html_dependency_jqueryui()
set.seed(1)
```
```{r 'Libraries', echo=FALSE, results='hide'}
library("tidyverse")
library("htmltools")
library("DT")
```
```{r 'Custom Fns'}
#Function for t-test Critical Values, Confidence interval, t-statistic & p-value
#given a vector of descriptive variables, or data
#Inputs:
#cl = confidence level in decimal form
#data = either sample data in vector form, or descriptive variables in vector form. Descriptive variables are c(bar_{x},mu,s,n)
#Outputs: 
#for data - a confidence interval
#for descriptive statistics: a tibble with Critical t values, a Confidence interval, the t-Statistic for bar_{x}, the pValue for bar_{x} 
tCrit <- function(cl,data,tail){
  pV <- function(x,data){ pv <- pt(x,df=data[4]-1)
    return(pv)}
  cI <- function(cV,data){CI <- c(data[2]-(qt(cV,data[4]-1)*data[3]/sqrt(data[4])),data[2]+(qt(cV,data[4]-1)*data[3]/sqrt(data[4])))
    return(CI)}
  tS <- function(data){tS <- (data[1]-data[2])/(data[3]/sqrt(data[4]))
  return(tS)}
  if(length(data)==4){
    if(tail=="2"|tail==2){
  cV <- (1-cl)/2+cl
  CI <- cI(cV,data)
  ts <- tS(data)
  lc <- -1*qt(cV,data[4]-1)
  hC <- qt(cV,data[4]-1)
  pv <- 2*pV(-1*abs(ts),data)
  cValues <- tibble::tribble(
    ~Variable,~Values,
    'Low tCrit', lc,
    'High tCrit', hC,
    'Conf_Int.Low', CI[1],
    'Conf_Int.Hi', CI[2],
    'T Statistic',ts,
    'pValue', pv
    )
  return(cValues)
  }else{
    if(tail=="L"|tail=="l"){
    cV <- (1-cl)
   CI <- cI(cV,data)
  ts <- tS(data)
    lc <- qt(cV,data[4]-1)
    pv <- pV(ts,data)
  cValues <- tibble::tribble(
    ~Variable,~Values,
    "Low tCrit", lc,
    'Conf_Int.Low', CI[1],
    'Conf_Int.Hi', CI[2],
    "T Statistic", ts,
    'pValue', pv
    )
  return(cValues)
    }else{
      if(tail=="R"|tail=="r"){
        cV <- cl
        CI <- cI(cV,data)
        ts <- tS(data)
        hc <- qt(cV,data[4]-1)
        pv <- 1-pV(ts,data)
         cValues <- tibble::tribble(
    ~Variable,~Value,
    "High tCrit",hc,
    'Conf_Int.Low', CI[1],
    'Conf_Int.Hi', CI[2],
    "T Statistic",ts,
    'pValue', pv
    )  
      return(cValues)
      }
    }
  }
  }else if(length(data)>4 | length(data)<4){
    if(tail=="2"|tail==2){
    x <- (1-cl)/2+cl
  CI <- c(mean(data)-qt(x,length(data)-1)*sd(data)/sqrt(length(data)),mean(data)+qt(x,length(data)-1)*sd(data)/sqrt(length(data)))
  cValues <- tibble::tribble(
    ~Variable,~Value,
    "High tCrit",qt(cV,data[4]-1),
    'Conf_Int', CI,
    "T Statistic",tS
    )  
      return(cValues)
  cV <- (1-cl)/2+cl
  }else{
    if(tail=="L"|tail=="l"){
    x <- (1-cl)
  CI <- c(mean(data)-qt(x,length(data)-1)*sd(data)/sqrt(length(data)),mean(data)+qt(x,length(data)-1)*sd(data)/sqrt(length(data)))
  return(CI)
  return(cValues)
    }else{
      if(tail=="R"|tail=="r"){
        x <- cl
        x <- (1-cl)/2+cl
  CI <- c(mean(data)-qt(x,length(data)-1)*sd(data)/sqrt(length(data)),mean(data)+qt(x,length(data)-1)*sd(data)/sqrt(length(data)))
  return(CI)
        }
      }
    }
  }else{return(NA)}
}
#2 Tailed t-test
#Inputs: 
#cl = confidence level
#m1,m2 = means of sample 1 & 2
#s1,s2 = standard deviations of sample 1 & 2
#n1,n2 = number of obs for sample 1 & 2
#m0 = Allows adjustment to the difference you want to test for, default 0
#var = Are the variances close enough to pool the samples?F=no, T=Yes, default F
#Output:
#tibble with statistic names in col1 '$variables' and values in col2 '$values'
#See tibble labels for each output
t.2 <- function(cl,m1,m2,s1,s2,n1,n2,m0=0,var=F){
  pV <- function(x,df){ pv <- 2*pt(-abs(x),df)}
  cV <- (1-cl)/2+cl
    if(var==FALSE){
        se <- sqrt((s1^2/n1)+(s2^2/n2))
        df <- ((s1^2/n1+s2^2/n2)^2)/((s1^2/n1)^2/(n1-1)+(s2^2/n2)^2/(n2-1))
    }else{
      df <- n1+n2-2
      sd <- sqrt(((n1-1)*s1^2+(n2-1)*s2^2)/df)
      se <- sqrt((1/n1+1/n2))*sd 
    }
    t <- (m1-m2-m0)/se
    lc <- -1*qt(cV,df)
    hc <- qt(cV,df)
    pv <- pV(t,df)
    t2 <- tibble::tribble(
      ~Variables,~Values,
      "meanDiff", m1-m2,
        "SE",se,
      "lCrit",lc,
      "hCrit",hc,
      "t",t,
      "pValue",pv
      )
    return(t2) 
}
```


<button data-toggle="collapse" data-target="#demo" class="btn">Homework Outline</button>
<div id="demo" class="collapse">
1.
You hypothesize that the average person is smarter than Sarah Palin. You know her IQ is 100.
You give an IQ test to 100 randomly selected people, and get a mean of 104 and standard deviation
of 22. Please show your work for each question.
a. What is your null hypothesis?
b. What is your research hypothesis?
c. What is your test statistic?
d. Do you prefer a one-tailed or two-tailed test here, and why?
e. What is your alpha and threshold (t statistic) value or values for your rejection region? (Whatever alpha you
prefer is fine, just be sure to state it and explain why you chose it.)
f. Can you reject the null under a one-tailed test?
g. Can you reject the null under a two-tailed test?
h. What is your 95% confidence interval?
i. What is the p-value for your test results?
2.
You hypothesize that men and women have different skill levels in playing Tetris. To test this,
you have 50 men and 50 women play the game in a controlled setting. The mean score of the men
is 1124 with a standard deviation of 200 and the mean score for the women is 1245, also with a
standard deviation of 200.
a. Are these scores statistically significantly different? Show your work.
b. Do you reject your hypothesis or the null? What do you conclude from this experiment?
3.
You think drinking the night before an exam might help performance on the exam the next
morning. To test this, you select 100 of your closest friends, and randomly get 50 of them drunk
the night before the exam, which you denote the treatment group. The next day, the treatment
group gets a mean of 78 with a standard deviation of 10 and the control group gets a 75 with a
standard deviation of 5.
a. Does the evidence show that drinking helped exam performance?
4.
1
Using data of your choosing (or using simulated data), use R to conduct the following tests, and
explain the results you get:
a. A standard one-sample hypothesis test.
b. A difference-in-means test with independent samples.
c. A difference-in-means test with dependent samples (ie, a paired t-test).
d. Manually verify the results in (a) using the mean and sd as calculated by R (ie, you don’t have to
manually calculate the mean or sd by hand!).
</div>

#Homework 5
## 1
You hypothesize that the average person is smarter than Sarah Palin. You know her IQ is 100. You give an IQ test to 100 randomly selected people, and get a mean of 104 and standard deviation of 22. Please show your work for each question.

### a.
What is your null hypothesis?
$H_0=\mu=100$

### b. 
What is your research hypothesis?
$H_a=\mu>100$

### c. 
What is your test statistic?
Since there are 100 obs in the sample, the data is expected to follow a normal distribution, and the z-stat should be sufficient.
$z = \frac{x – \bar{'x}}{s}$  
$z = \frac{104 – 100}{22}$  
$z = \frac{4}{22}$  
$z = .1818$  
or if you're looking for the t-statistic:
$t_{stat}=\frac{\bar{x}-\mu}{\frac{s}{\sqrt{n}}}$  
$t_{stat}=\frac{104-100}{\frac{22}{\sqrt{100}}}$  
$t_{stat}=1.818$  
```{r '1c'}
zs <- function(x,mu,sd) {
  z <- (x-mu)/sd
  return(z)
}
(z <- zs(104,100,22))
tCrit(.95,c(104,100,22,100),"r")
```

### d. 
Do you prefer a one-tailed or two-tailed test here, and why?
<div class="a">A)A one-tailed test because of the question and the alternative hypothesis. In the question, the sample mean and st.dev are already given, and the mean is slightly higher than 100. A two-tailed test might have made more sense because the mean could have been < or > 100, but in this case we already know the sample mean. Additionally, the alternative hypothesis is that the average person is smarter, so we're looking for the $\bar{x}$ to be greater than $\mu$ by some statistically significant measure.</div>
### e. 
What is your alpha and threshold (t statistic) value or values for your rejection region? (Whatever alpha you prefer is fine, just be sure to state it and explain why you chose it.)
<div class="a">A)$\alpha=.05$, I chose the .05 alpha level because it will have a $\frac{1}{20}$ chance of being accurate. Given the high standard deviation, it's intuitively highly unlikely that the alternative hypothesis will be supported at the .01 level, and at the .1 alpha level the conclusion could be inaccurate 1 in 10 times. The middle ground, or a .05 alpha level seems appropriate. The $t_{crit}=1.72$. This wording in the question is confusing because t-statistic is usually defined by $t_{stat}=\frac{\bar{x}-\mu}{\frac{s}{\sqrt{n}}}$ and it provides the value to compare to the $t_{crit}$ to test the hypothesis. I am assuming based on the context of it's appearance: <em>"threshold (t statistic) value or values for your rejection region"</em> that what's being sought is the critical t value(s). </div>
```{r '1e'}
tCrit(.95,c(104,100,22,100),"r")
```

### f. 
Can you reject the null under a one-tailed test?
<div class="a">A)If $t_{stat}>t_{crit}$  then the null hypothesis can be rejected. The calculation below indicates the null can be rejected in a one tailed test.
$t_{stat}=1.818>t_{crit}=1.66$
</div>
```{r '1f'}
tCrit(.95,c(104,100,22,100),"r")
```


### g. 
Can you reject the null under a two-tailed test?
<div class="a">The upper $t_{crit}$ is higher in a two tailed test, thus the test statistic no longer falls within the rejection region. With a two-tailed test we fail to reject the null hypothesis.
$t_{stat}=1.818<t_{crit}=1.984$</div>
```{r '1g'}
tCrit(.95,c(104,100,22,100),"2")
```

### h. 
What is your 95% confidence interval?
$\text{Confidence Interval}:CI=\bar{x}\pm t*\frac{s}{\sqrt{N}}$  
$CI=100\pm 1.984*\frac{22}{\sqrt{100}}$  
$CI=100\pm 4.3648$  
```{r '1h'}
tCrit(.95,c(104,100,22,100),"2")
```

### i. 
What is the p-value for your test results?
<div class="a">A)It seems like everyone is saying something different about how a $p_{value}$ relates to one v two tailed tests. Based on the information in this <a href="https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-what-are-the-differences-between-one-tailed-and-two-tailed-tests/" target="_blank">tutorial</a>, the $p_{value}$ is different depending on the test. IE for a 2 tailed test it is: 
$p_{value}=2*∫^{x}_{−∞}f(-|t_{stat}|)dt$  
for a Left tailed test it is:
$p_{value}=∫^{x}_{−∞}f(t_{stat})dt$  
and for a Right tailed test it is:
$p_{value}=1-∫^{x}_{−∞}f(t_{stat})dt$  
Based on these formulas, the $p_{value}$ is <code>.03</code> for the right tailed test, rejecting the null hypothesis, and is <code>.07</code> for the 2 tailed test, failing to reject the null hypothesis.
</div>
```{r '1i'}
tCrit(.95,c(104,100,22,100),"2")

```

## 2.
You hypothesize that men and women have different skill levels in playing Tetris. To test this, you have 50 men and 50 women play the game in a controlled setting. The mean score of the men is 1124 with a standard deviation of 200 and the mean score for the women is 1245, also with a standard deviation of 200.

### a.
Are these scores statistically significantly different? Show your work.
<div class="a">A) Since the standard deviations are identical, the samples can be pooled, thus we first solve for the pooled standard deviation: 
$s_p=\sqrt{\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}$  
$s_p=\sqrt{\frac{(50-1)200^2+(50-1)200^2}{50+50-2}}$  
$s_p=\sqrt{40000}$  
$s_p=200$  
Probably should have guessed 200 would be the $s_p$ with identical $n$ and $s$ in the two samples. The next step is to solve for the $t_{stat}$  
$t_{stat}=\frac{\bar{x}_1-\bar{x}_2}{s_{p}*\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}$  
$t_{stat}=\frac{1124-1245}{200*\sqrt{\frac{1}{50}+\frac{1}{50}}}$  
$t_{stat}=\frac{-121}{200*.2}}$  
$t_{stat}=-3.025$  
Then find the degrees of freedom to establish the $t_{crit}$
$df_{s1=s2}=n_1+n_2-2$  
$df_{s1=s2}=50+50-2$
</div>
```{r '2a'}
t.2(.95,1124,1245,200,200,50,50,var=T)
```

### b. 
Do you reject your hypothesis or the null? What do you conclude from this experiment?
<div class="a">A)At the 95% confidence level the null hypothesis can be rejected in favor of the research hypothesis. It can be concluded that at the 95% confidence level there is a statistically signicant difference between the Tetris skills of males v females.</div>


## 3.
You think drinking the night before an exam might help performance on the exam the next morning. To test this, you select 100 of your closest friends, and randomly get 50 of them to drink the night before the exam, which you denote the treatment group. The next day, the treatment group gets a mean of 78 with a standard deviation of 10 and the control group gets a 75 with a standard deviation of 5.

### a. 
Does the evidence show that drinking helped exam performance?
<div class="a">A)In this example, the standard deviations are different enough where it would be misleading to pool them. We can first compute the $t_{stat}$:
$t_{stat}=\frac{{\bar{x}}_1-{\bar{x}}_2}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}$  
$t_{stat}=\frac{78-75}{\sqrt{\frac{100}{50}+\frac{25}{50}}}$  
$t_{stat}=\frac{3}{1.581139}$  
$t_{stat}=1.897367$  
and then the degrees of freedom:
$df=\frac{(n_1-1)*(n_2-1)}{(n_2-1)C^2+(1-C)^2(n_1-1)}\text{ where } C=\frac{s_1^2/n_1}{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}$  
$C=\frac{100/50}{\frac{100}{50}+\frac{25}{50}}$  
$C=\frac{2}{2.5}$  
$C=0.8$
$df=\frac{(49)*(49)}{(49).8^2+(1-.8)^2(49)}$  
$df=\frac{2401}{33.32}$  
$df=72.059$  
With this degree of freedom the critical value is 1.993436, the $t_{stat}=1.897367$ and does not fall within the rejection region, so at the 95% confidence level we fail to reject the null hypothesis and conclude that drinking before an exam does not improve exam performance.</div>
```{r '3a'}
#tstat
(ts <- 3/sqrt(100/50+25/50))
#df
(c <- 2/2.5)
(df <- 49*49/((49)*.8^2+(1-.8)^2*(49)))
#Critical Value
qt(.975,df)
t.2(.95,78,75,10,5,50,50,var=F)
```


## 4.
Using data of your choosing (or using simulated data), use R to conduct the following tests, and explain the results you get:
### a. 
A standard one-sample hypothesis test.

### b. 
A difference-in-means test with independent samples.

### c. 
A difference-in-means test with dependent samples (ie, a paired t-test).

### d. 
Manually verify the results in (a) using the mean and sd as calculated by R (ie, you don’t have to manually calculate the mean or sd by hand!).
